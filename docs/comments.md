잘린 부분을 확인해야 한다.논문 전체를 검토했다. AI 전문가 관점에서 체계적으로 심사 의견을 제시한다.

---

# 논문 심사 의견서

## 논문 제목
"Can Indigenous LLMs Better Simulate Local Survey Responses? Evidence from Korean Cultural Variables"

---

## 1. 총평

본 논문은 LLM 기반 설문조사 시뮬레이션("Silicon Sampling")에서 토착 LLM(CLOVA HCX-007)이 글로벌 LLM(GPT 계열)보다 문화 특수적 응답 분포를 더 잘 복제하는지를 검증한 연구이다. 연구 주제의 시의성과 실용적 함의가 높으며, 체계적인 ablation study 설계와 통계적 검증 프레임워크 제시는 긍정적으로 평가된다. 그러나 방법론적 한계, 통계 해석상의 문제, 그리고 일부 과잉 일반화된 주장에 대해 수정이 필요하다.

**종합 판정**: 수정 후 재심사(Major Revision)

---

## 2. 강점

### 2.1 연구 주제의 중요성 및 시의성

LLM을 활용한 합성 데이터 생성은 AI 연구의 주요 흐름 중 하나이며, 비서구권 문화 맥락에서의 LLM 편향 문제를 다룬 점은 학술적, 실무적 가치가 높다. 특히 토착 LLM과 글로벌 LLM의 비교라는 연구 설계는 자연 실험(natural experiment)의 형태로 인과적 함의를 탐색할 수 있는 기반을 제공한다.

### 2.2 체계적인 실험 설계

5개의 ablation study(온도, 추론 전략, 프롬프트 언어, 모델 버전, 토착 vs. 글로벌)를 통해 개별 요인의 효과를 분리하려는 시도는 방법론적으로 적절하다. 각 ablation이 단일 변수를 조작하면서 다른 조건을 통제한 점은 내적 타당성 확보에 기여한다.

### 2.3 통계적 검증 프레임워크

JS divergence와 KS 검정의 조합, bootstrap 신뢰구간, 효과 크기(Cramér's V), TOST 동등성 검정, FDR 보정 등 다층적 통계 분석을 수행한 점은 결과의 신뢰성을 높인다. 특히 KS 검정의 비유의성이 동등성의 증거가 아님을 명시하고 검정력 분석을 제시한 것은 통계적 엄밀성을 보여준다.

### 2.4 한계점의 명시적 인정

Section 5.4에서 내적/외적/구성/통계적 결론 타당성에 대한 위협을 체계적으로 기술한 것은 학술적 정직성 측면에서 긍정적이다.

---

## 3. 약점 및 개선 요구 사항

### 3.1 방법론적 문제

#### 3.1.1 페르소나 설계의 불투명성 (Critical)

논문은 "consistent persona prompts describing a representative Korean adult"(line 94)를 사용했다고 언급하나, 구체적인 페르소나 구성 방식이 제시되지 않았다. 

**문제점**: 
- 페르소나가 단일 유형인지, 다양한 인구통계학적 프로필을 반영하는지 불명확
- KGSS의 실제 표본 구성(성별, 연령, 지역, 교육 수준 등)을 페르소나에 반영했는지 여부 불명
- 페르소나 설계가 응답 분포에 미치는 영향이 ablation에 포함되지 않음

**요구 사항**: Appendix에 페르소나 프롬프트의 전문을 공개하고, 페르소나 설계 방법론을 상세히 기술할 것. 가능하다면 페르소나 변이에 대한 ablation을 추가할 것.

#### 3.1.2 n=100의 표본 크기 정당화 부재

조건당 100개의 응답을 생성한 근거가 제시되지 않았다. 

**문제점**:
- 검정력 분석(line 222-227)에서 n=100이 소효과 탐지에 11.57% 검정력밖에 제공하지 못함을 인정
- 그러나 이는 사후(post-hoc) 분석이며, 사전 검정력 분석 없이 표본 크기를 결정한 것으로 보임
- 100이라는 숫자가 비용-효과 trade-off의 결과인지, 이론적 근거가 있는지 불분명

**요구 사항**: 표본 크기 결정의 근거를 명시하고, 가능하다면 추가 실험으로 표본 크기를 증가시킬 것(최소 n=300 권장).

#### 3.1.3 단일 실험 실행(Single Run)의 한계 (Critical)

각 조건에서 단일 실험만 수행된 것은 결과의 재현성에 심각한 위협이다.

**문제점**:
- LLM 응답은 동일 조건에서도 변동성이 존재(특히 temperature > 0)
- bootstrap은 생성된 100개 응답 내 변동성만 추정하며, 실험 간 변동성(inter-run variability)은 포착하지 못함
- 단일 run에서 우연히 좋은/나쁜 결과가 나왔을 가능성 배제 불가

**요구 사항**: 최소 5회 이상의 독립적 실험 실행을 수행하고, 실험 간 분산을 보고할 것.

### 3.2 통계 분석 및 해석의 문제

#### 3.2.1 JS Divergence 임계값의 자의성

JS < 0.05를 "substantial similarity"의 탐색적 기준으로 제시했으나(line 97), 이 임계값의 근거가 불분명하다.

**문제점**:
- "following conventions in distribution comparison literature"라는 언급이 있으나 구체적 인용 없음
- 실제 결과에서 이 임계값을 충족한 것은 CLOVA의 UNIFI(0.020)뿐이며, 주요 결과로 강조된 CONFINAN(0.063)도 미달
- 임계값 설정에 따라 결론이 달라질 수 있음

**요구 사항**: JS < 0.05 기준의 출처를 명시하거나, 여러 임계값에서의 민감도 분석(sensitivity analysis)을 추가할 것.

#### 3.2.2 KS 검정 해석의 논리적 문제

CLOVA의 CONFINAN에서 KS p=0.103이 "successful statistical replication"(line 172)이라고 표현되었으나, 이는 귀무가설검정의 논리를 위배한다.

**문제점**:
- p > 0.05는 귀무가설을 기각하지 못한 것이지, 귀무가설이 참임을 증명하지 않음
- 논문 자체에서도 이를 인정(line 99, 227)하면서도 "successful replication"이라는 표현을 반복 사용
- TOST 검정을 추가했으나, equivalence margin δ=0.05의 근거가 불명확

**요구 사항**: "successful replication" 표현을 "failure to reject null hypothesis" 또는 유사한 중립적 표현으로 수정할 것. TOST의 δ 설정 근거를 명시할 것.

#### 3.2.3 Ablation D와 E 간 변수 불일치

Ablation D(GPT-4o-mini vs. GPT-5.2)는 4개 변수(SATFIN, PARTYLR, NORTHWHO, UNIFI), Ablation E(CLOVA vs. GPT-5.2)는 6개 변수(CONFINAN, CONLEGIS, KRPROUD, NORTHWHO, UNIFI, PARTYLR)를 사용했다.

**문제점**:
- SATFIN은 Ablation D에만, CONFINAN/CONLEGIS/KRPROUD는 Ablation E에만 포함
- 두 ablation 간 직접 비교가 불가능
- Table (line 69)에서 제시된 6개 변수와 Ablation D의 변수 목록이 불일치(SATFIN은 Table에 없음)

**요구 사항**: 변수 선정의 불일치 이유를 설명하거나, 동일 변수 세트로 재분석할 것.

### 3.3 주장의 과잉 일반화

#### 3.3.1 인과적 언어의 부적절한 사용

"Indigenous LLM Advantage" (Section 5.1)라는 표현은 상관관계를 인과관계로 해석하는 경향이 있다.

**문제점**:
- CLOVA와 GPT의 차이가 "토착성" 때문인지, 모델 아키텍처, 학습 데이터 규모, 파인튜닝 방법론 등 다른 요인 때문인지 분리 불가
- "likely stems from" (line 244)라는 표현으로 완화했으나, 제목과 결론에서는 인과적 함의가 강함

**요구 사항**: 제목의 "Better"를 "Show Closer Alignment"로, "Indigenous LLM Advantage"를 "Indigenous LLM Association" 등으로 수정하여 인과적 함의를 완화할 것.

#### 3.3.2 결론의 과도한 일반화

"indigenous LLMs may be essential for valid survey simulation in non-Western contexts" (line 6)는 단일 LLM, 단일 국가, 단일 설문조사에 기반한 과도한 주장이다.

**요구 사항**: "may contribute to improved alignment" 등으로 표현을 완화하고, 일반화의 한계를 명시할 것.

### 3.4 재현성 및 투명성

#### 3.4.1 GPT-5.2의 존재 여부 (Critical)

2024년 12월 기준 OpenAI의 최신 모델은 GPT-4o 계열이며, "GPT-5.2"라는 모델은 공개적으로 알려진 바 없다.

**요구 사항**: 실제 사용한 모델의 정확한 명칭과 버전을 확인하고 수정할 것. 모델명이 가상인 경우, 논문의 신뢰성에 심각한 문제가 있음.

#### 3.4.2 CLOVA HCX-007 접근성

CLOVA HCX-007의 API 접근 가능 여부, 비용, 제한 사항 등이 명시되지 않아 재현성이 제한된다.

**요구 사항**: 모델 접근 방법을 Appendix에 상세히 기술할 것.

---

## 4. 세부 수정 사항

| 위치 | 현재 내용 | 수정 요구 |
|------|----------|----------|
| Title | "Can Indigenous LLMs Better Simulate" | 인과 함의 완화 필요 |
| Line 5 | "59.8% lower JS divergence on average" | 95% CI 함께 제시 |
| Line 21 | "the only successful statistical non-significance" | "the only case where we failed to reject the null" 등으로 수정 |
| Line 75-77 | GPT-5.2 (December 2024) | 모델명 검증 필요 |
| Line 91 | "4 core variables" footnote | SATFIN이 Table에 없음. 변수 정의 추가 필요 |
| Line 172 | "Successful Replication" | "Failed to Reject" 등으로 수정 |
| Line 286 | "successful statistical replication" | 표현 완화 |
| Appendix | 프롬프트 미공개 | 전문 공개 필요 |

---

## 5. 추가 권장 사항

1. **추가 토착 LLM 비교**: CLOVA 외에 다른 한국어 LLM(예: KakaoBrain의 KoGPT, LG AI Research의 EXAONE)과의 비교를 통해 "토착성"의 일반화 가능성 검증

2. **변수별 오류 분석**: 각 변수에서 LLM이 생성한 응답 분포와 KGSS 분포의 구체적 차이 패턴 분석(예: 어떤 응답 범주에서 과대/과소 추정이 발생하는지)

3. **정성적 분석**: LLM이 생성한 응답의 일관성, 논리성 등에 대한 정성적 평가 추가

4. **다른 문화권 확장**: 일본, 중국 등 다른 아시아 국가의 토착 LLM과 글로벌 LLM 비교를 통한 외적 타당성 검증

---

## 6. 결론

본 논문은 중요한 연구 질문을 다루며, 체계적인 실험 설계와 다층적 통계 분석을 수행했다는 점에서 가치가 있다. 그러나 핵심적인 방법론적 한계(단일 실험 실행, 페르소나 불투명성, 모델명 검증 필요)와 통계 해석상의 문제(귀무가설검정 논리 위배)가 있어, 이를 해결한 후 재심사가 필요하다. 특히 GPT-5.2라는 모델명의 정확성이 확인되어야 하며, 확인되지 않을 경우 논문의 신뢰성에 근본적 문제가 발생한다.

---

**심사자 권고**: Major Revision

다음은 첨부 원고(“Can Indigenous LLMs Better Simulate Local Survey Responses? …”)에 대한 **전문가 심사 의견**입니다. 

## 1) 원고 요약 (기여/핵심 주장)

본 연구는 KGSS 2023 분포를 벤치마크로 삼아, LLM이 설문 응답 분포를 얼마나 재현하는지 **Silicon Sampling** 프레임워크(JS divergence, KS test 등)로 평가하고, GPT 계열과 한국어 토착(Indigenous) LLM(CLOVA HCX-007)을 비교합니다. 
주요 결과로는 **CLOVA가 6개 변수 중 5개에서 GPT-5.2보다 JS가 낮고(평균 0.071 vs 0.183), KS에서 유일하게 비유의(p=0.103)를 얻은 변수가 CONFINAN**이라고 주장합니다. 

## 2) 강점

* **문제의식이 명확**합니다: “비서구/로컬 문화 변수에서 LLM 분포 재현이 가능한가?”라는 질문을 토착 LLM 비교로 정면화합니다. 
* 단일 결과 보고가 아니라, **온도/추론(CoT)/언어/모델세대/토착 vs 글로벌** 등 **요인별 소규모 ablation**을 구성해 구조적으로 설명하려는 시도가 있습니다. 
* KS 비유의 해석의 한계(“비유의=동일성 증명 아님, n=100의 파워 한계”)를 스스로 명시한 점은 좋습니다. 

## 3) 주요 쟁점 (Major Concerns) — 출판을 위해 반드시 보완 필요

### (A) “대표적 한국 성인 1개 페르소나”로 **모집단 분포 재현을 주장**하는 설계 불일치

원고는 “대표적 Korean adult 페르소나”로 조건당 n=100을 생성해 **모집단(전국대표 표본 n≈1,500)의 주변분포**와 직접 비교합니다.  
하지만 모집단 분포는 (성별/연령/지역/학력/이념 등) **구성비의 혼합(mixture)** 결과인데, 단일 페르소나 샘플링은 이 혼합을 구조적으로 재현하기 어렵습니다. 즉, “문화적 정렬” 효과가 아니라 “특정 페르소나의 응답 경향이 KGSS 혼합분포와 우연히 가까워진 것”일 가능성을 배제하기 어렵습니다.
➡️ 최소한 **KGSS 분포를 구성하는 인구학적 층화(또는 post-stratification)**를 설계에 포함시키거나, “모집단 재현”이 아니라 “특정 하위집단(예: 30대 남성 수도권 등) 재현”으로 목표를 재정의해야 합니다.

### (B) 통계검정 선택(특히 KS)의 적합성: **이산/서열형 척도에 KS를 그대로 쓰는 문제**

대부분 변수가 1–4, 1–5 같은 **서열형(ordinal) 범주**이고, PARTYLR도 0–10의 **이산형**입니다. 
KS는 원래 연속형 분포 비교에 강점이 있으며, 이산 분포에서의 p-value 해석은 보수적/왜곡될 수 있습니다(동점(ties) 처리 문제). 현재 “KS 비유의=성공”처럼 핵심 결론에 사용하고 있어, 검정 선택이 결과 해석을 좌우합니다. 
➡️ 범주형/서열형에서는 **카이제곱/우도비(G-test)**, **Cramér’s V**, **서열형 거리(예: Earth Mover’s Distance/ Wasserstein-1 for ordinal bins)** 같은 지표를 주지표로 두는 것이 더 타당합니다. (KS는 보조로 두되 이산형 보정/퍼뮤테이션 기반 p-value 등을 권장)

### (C) 재현가능성(Replicability) 부족: 프롬프트·샘플링·시드·API 세부가 결론을 지배

“페르소나 기반 프롬프트”라고만 되어 있고 프롬프트 전문, 응답 후처리(무응답/중립 처리), 무작위성 통제(시드/샘플링) 등이 본문 수준에서 충분히 공개되지 않습니다. 
또한 CoT 사용은 모델 정책/버전에 따라 출력 안정성이 달라지고(특히 공개될 때), 실험 재현이 어렵습니다. 
➡️ **(1) 프롬프트 전문/템플릿, (2) 응답 매핑 규칙(자연어→선다형), (3) 샘플링 파라미터(temperature 외 top_p 등), (4) 반복실험(여러 run)과 run 간 변동**을 필수로 공개해야 합니다.

### (D) 표/변수 정의의 불일치: SATFIN 등장 및 변수 세트 혼선

Ablation D에서 “SATFIN”이 등장하는데, 앞서 선택 변수 표에는 SATFIN이 없습니다.  
이 정도의 변수 정의 혼선은 결과 신뢰도를 크게 떨어뜨립니다(코딩 실수/다른 항목 사용 가능성).
➡️ 변수명/스케일/응답범주/결측처리까지 **코드북 기반으로 엄밀히 일치**시키고, 본문과 표 전체를 정리해야 합니다.

### (E) JS 임계값(“<0.05면 상당한 유사”)의 근거 부족 + TOST를 JS에 적용한 정당화 부족

JS<0.05를 “관행”으로 두었다고 하지만, 설문 범주 수/표본 크기/분포 형태에 따라 JS의 해석은 달라집니다. 
또 “TOST equivalence test(δ=0.05)”를 JS에 적용한 것은 흥미롭지만 표준적 접근은 아니며, **δ 선택 근거**와 **JS의 표본분포/검정 통계량 구성**이 설득력 있게 제시되어야 합니다. (현재는 결론만 제시되는 인상)

## 4) 경미한 수정사항 (Minor)

* “첫 번째 체계적 비교(first systematic comparison)” 같은 강한 최초성 주장은 문헌 커버리지/정의에 따라 반박될 수 있으니 표현을 완화하거나 근거를 보강하세요. 
* “repository URL to be added”는 제출 시점엔 허용되기 어렵습니다. 재현성 패키지(코드/프롬프트/집계표)를 반드시 제공해야 합니다. 
* 모델 버전 표기는 “gpt-5.2”처럼 넓게 적기보다, 실제 사용한 **정확한 모델 식별자/날짜/엔드포인트/파라미터**를 더 엄밀히 기재해야 합니다. 

## 5) 권고되는 추가 실험/분석 (가장 효과 큰 것부터)

1. **층화 페르소나 + 후층화(post-stratification)**: KGSS 인구학 분포(가중치 포함)를 따라 여러 페르소나에서 응답 생성 → 가중합으로 “모집단 분포” 재구성.
2. **반복 실험(R≥10) + 불확실성 보고**: 조건당 n=100을 10회 이상 반복해 JS/거리 지표의 분산을 보고. (“single run” 한계를 본문에서 이미 인정) 
3. **검정체계 재정비**: 서열형은 (i) EMD/Wasserstein-1, (ii) 카이제곱/우도비, (iii) 효과크기(이미 일부 제시) 중심으로. KS는 보조/퍼뮤테이션 기반으로.
4. **응답 매핑의 신뢰도 점검**: 모델이 자연어로 답했을 때 선다형으로 매핑하는 규칙이 있다면, 매핑 오류가 분포를 만들 수 있으니 inter-rater/규칙 검증 필요.
5. **공정 비교**: 동일 언어/동일 지시문/동일 안전필터 조건에서 모델 비교(특히 토착 LLM과 글로벌 LLM의 시스템 프롬프트 차이 가능성 통제).

## 6) 종합 판정

현 단계에서는 **Major Revision(대폭 수정 후 재심)**이 타당합니다.
핵심 아이디어(토착 LLM의 문화 변수 분포 정렬 가능성)는 충분히 흥미롭고, 결과도 유의미해 보이지만(예: CLOVA의 평균 JS 개선 및 CONFINAN의 KS 비유의 주장) ,
현재 설계(단일 대표 페르소나), 검정 선택(KS의 중심 사용), 변수 정의 혼선(SATFIN) 등은 결론의 내부타당도/재현가능성을 크게 약화시킵니다. 

