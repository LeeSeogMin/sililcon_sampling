# 실리콘 샘플링 방법론의 체계적 검증: KGSS 2023을 활용한 다중 실험 연구

**A Systematic Validation of Silicon Sampling Methodologies: A Multi-Experiment Study Using KGSS 2023**

---

## Abstract

**배경**: 실리콘 샘플링(Silicon Sampling) 옹호자들은 인구학적 페르소나, Temperature 조정, Chain-of-Thought(CoT) 추론, 프롬프트 엔지니어링, 모델 발전 등 다양한 방법론이 LLM 기반 설문조사 시뮬레이션의 정확도를 향상시킨다고 주장한다. 그러나 이러한 방법론들에 대한 체계적 검증과 함께, 비서구권에서의 문화적 맥락 효과에 대한 연구는 부족한 실정이다.

**목적**: 본 연구는 두 가지 연구 축을 통해 실리콘 샘플링을 체계적으로 검증한다: (1) 방법론 효과성 검증, (2) 모델 발전과 문화적 맥락의 영향. 특히, LLM 발전이 실리콘 샘플링 가능성을 높이는지, 그리고 토착 LLM이 서구 LLM보다 해당 문화권 시뮬레이션에서 우수한지를 검증한다.

**방법**: 한국종합사회조사(KGSS) 2023을 벤치마크로 6개 실험을 수행하였다:
1. **기본 시뮬레이션**: 인구학적 페르소나를 통한 분포 재현
2. **Temperature 최적화**: T=0.3~1.1 범위에서 최적 파라미터 탐색
3. **Chain-of-Thought(CoT)**: 중간 추론 과정의 효과 검증
4. **프롬프트 엔지니어링**: 3가지 전략 비교
5. **모델 발전**: GPT-4o-mini vs GPT-5.2 성능 비교
6. **문화적 맥락**: GPT-5.2(서구 LLM) vs CLOVA HCX-007(한국 토착 LLM) 비교

각 실험은 Jensen-Shannon(JS) Divergence를 사용하여 KGSS 실제 분포와의 일치도를 측정하였다.

**결과**:

*Part I: 방법론 효과성*
- **기본 시뮬레이션**: 7개 변수 모두에서 통계적으로 유의한 차이 (평균 JS=0.397)
- **Temperature 최적화**: 일부 변수에서 개선 (SATFIN: 43.7% 개선)
- **Chain-of-Thought**: 비일관적 결과, 권장하지 않음
- **프롬프트 엔지니어링**: "극단 허용" 전략이 최우수 (평균 24.2% 개선)

*Part II: 모델 발전과 문화적 맥락*
- **모델 발전**: GPT-5.2가 GPT-4o-mini 대비 평균 22.6% 개선 → LLM 발전이 실리콘 샘플링 가능성 제고
- **문화적 맥락**: CLOVA가 GPT-5.2 대비 **6개 변수 전체에서 평균 59.8% 개선**. 특히 국회 신뢰(77.1%), 대북 인식(77.7%) 등 정치/사회 변수에서 극적 격차. **CLOVA의 금융기관 신뢰(CONFINAN) 시뮬레이션은 KGSS와 통계적으로 유의한 차이 없음 (KS p=0.103)** → 토착 LLM의 실제 분포 재현 가능성 입증

**결론**: 본 연구는 두 가지 핵심 발견을 제시한다. 첫째, LLM의 발전은 실리콘 샘플링의 미래 가능성을 높인다. 둘째, 문화적 맥락은 실리콘 샘플링의 핵심 요소로, 비서구권 연구에서는 토착 LLM 사용이 필수적이다. 서구 LLM에 기반한 실리콘 샘플링 연구 결과를 비서구권에 일반화하는 것에 주의가 필요하며, 각 문화권에 맞는 LLM 선택이 방법론적 개선보다 더 큰 효과를 가져올 수 있다.

**키워드**: 실리콘 샘플링, 방법론 검증, 대규모 언어모델, 한국종합사회조사, 토착 LLM, CLOVA, 문화적 맥락, GPT-5.2

---

## 1. Introduction

### 1.1 연구 배경: 실리콘 샘플링 방법론 주장의 확산

대규모 언어모델(LLM)을 활용한 설문조사 시뮬레이션, 즉 "실리콘 샘플링(Silicon Sampling)"은 전통적 사회조사의 비용, 시간, 접근성 한계를 극복할 수 있는 혁신적 방법론으로 제안되어 왔다. Argyle et al.(2023)이 GPT-3를 사용한 미국 GSS 시뮬레이션에서 높은 정확도를 보고한 이후, 연구자들은 다양한 방법론적 개선을 제안해왔다.

그러나 이러한 방법론적 주장들은 대부분 개별 연구에서 독립적으로 검증되었으며, 통합적이고 체계적인 비교 연구는 부족한 실정이다. 더욱이 대부분의 연구가 영어권(특히 미국) 데이터에 집중되어 있어, 비서구권 맥락에서의 일반화 가능성은 미검증 상태이다.

### 1.2 검증 대상: 5가지 방법론적 주장

본 연구는 실리콘 샘플링 문헌에서 제안된 5가지 핵심 방법론적 주장을 체계적으로 검증한다:

**주장 1: 인구학적 페르소나 기반 시뮬레이션 (Argyle et al., 2023)**
> "LLM에 인구학적 특성(나이, 성별, 학력 등)을 명시한 페르소나를 제공하면, 해당 인구집단의 실제 응답 분포를 재현할 수 있다."

**주장 2: Temperature 파라미터 최적화**
> "Temperature 파라미터를 조정하여 응답 분포의 다양성을 최적화할 수 있다. 낮은 Temperature는 일관성을, 높은 Temperature는 다양성을 높인다."

**주장 3: Chain-of-Thought(CoT) 추론 (Dillion et al., 2023)**
> "응답 전 중간 추론 과정을 생성하도록 유도하면, 복잡한 질문에 대한 응답 품질이 향상된다."

**주장 4: 프롬프트 엔지니어링 (Ornstein et al., 2024)**
> "프롬프트의 구조와 내용을 최적화하면 응답의 정확도가 향상된다. 특히 구체적 맥락 제공과 명시적 지시가 효과적이다."

**주장 5: 모델 발전에 따른 성능 향상**
> "GPT-3 → GPT-4 → GPT-5로 모델이 발전할수록 시뮬레이션 정확도가 향상된다."

**주장 6: 문화적 맥락과 토착 LLM의 우위 (본 연구의 추가 검증)**
> "특정 문화권의 언어와 맥락을 집중 학습한 토착 LLM이 범용 서구 LLM보다 해당 문화권의 사회조사 시뮬레이션에서 우수한 성능을 보인다."

본 연구는 기존 5가지 주장에 더해, 한국어 특화 LLM인 CLOVA HCX-007과 GPT-5.2를 비교함으로써 문화적 맥락의 중요성을 실증적으로 검증한다. 이는 비서구권 학술 연구에서 자국 LLM 활용의 필요성과 가능성을 탐색하는 첫 번째 체계적 시도이다.

### 1.3 연구 질문

본 연구는 다음 연구 질문에 답하고자 한다:

**Part I: 방법론 검증**

**RQ1**: 각 방법론적 개선이 실제로 시뮬레이션 정확도를 향상시키는가?

**RQ2**: 방법론의 효과는 변수 특성(정치적 민감도, 사회적 바람직성)에 따라 어떻게 달라지는가?

**RQ3**: 어떤 방법론 조합이 가장 효과적이며, 실무 적용을 위한 가이드라인은 무엇인가?

**Part II: 모델 발전과 문화적 맥락**

**RQ4**: LLM의 발전(GPT-4o-mini → GPT-5.2)이 실리콘 샘플링의 실현 가능성을 높이는가?
> 모델 성능 향상이 시뮬레이션 정확도 개선으로 이어지는지, 그리고 이것이 실리콘 샘플링의 미래 가능성을 시사하는지 검증한다.

**RQ5**: 자국 문화 맥락을 학습한 LLM(CLOVA HCX-007)이 서구 LLM(GPT-5.2)보다 한국 사회조사 시뮬레이션에서 우수한 성능을 보이는가?
> 한국어와 한국 사회문화를 집중 학습한 토착 LLM의 학술 연구 활용 가능성을 탐색하고, 문화적 맥락이 실리콘 샘플링 성능에 미치는 영향을 분석한다.

### 1.4 연구의 의의

**학술적 기여**:
1. 실리콘 샘플링 방법론에 대한 최초의 체계적 통합 검증 연구
2. 비서구권(한국) 맥락에서의 방법론 효과성 검증
3. 방법론 선택을 위한 증거 기반 프레임워크 제시
4. **LLM 발전과 실리콘 샘플링 가능성의 관계 실증**: GPT-4o-mini에서 GPT-5.2로의 발전이 시뮬레이션 정확도 향상으로 이어짐을 입증하여, 미래 모델 발전에 따른 실리콘 샘플링의 실현 가능성 전망 제시
5. **문화적 맥락과 토착 LLM의 학술적 가치 입증**: 서구 LLM(GPT)과 한국 LLM(CLOVA)의 비교를 통해, 자국 문화 맥락을 학습한 LLM이 해당 사회의 조사 시뮬레이션에서 우수할 수 있음을 실증

**실무적 기여**:
1. 변수 특성별 최적 방법론 가이드라인
2. 방법론 조합의 비용-효과 분석
3. 실리콘 샘플링 적용 시 주의사항 및 한계 명시
4. **비서구권 연구자를 위한 LLM 선택 가이드**: 자국 LLM 활용의 장점과 고려사항 제시

---

## 2. Literature Review: 방법론적 주장과 이론적 기반

### 2.1 인구학적 페르소나 기반 시뮬레이션

Argyle et al.(2023)은 "algorithmic fidelity" 개념을 제안하며, LLM이 학습 데이터 속 인구집단별 언어 패턴과 태도 분포를 내재화하고 있다고 주장했다. 이 연구에서 GPT-3는 미국 GSS 15개 변수에 대해 평균 r=0.85의 상관관계를 보였다.

그러나 이 연구의 한계도 존재한다:
- 상관관계와 분포 일치도는 다른 개념
- 영어권 데이터에 국한된 검증
- 정치적 민감 변수에서 성능 저하 보고

### 2.2 Temperature 파라미터의 역할

Temperature는 LLM 출력의 확률 분포를 조정하는 핵심 파라미터이다. 수학적으로, Temperature T가 높아질수록 확률 분포가 평탄해져 다양한 응답이 생성되고, 낮아질수록 가장 가능성 높은 응답에 집중된다.

```
P(token) = softmax(logits / T)
```

이론적으로, 적절한 Temperature 조정은:
- 중앙화 편향(centralization bias) 완화
- 응답 다양성 증가
- 실제 분포와의 일치도 향상

을 가져올 수 있다. 그러나 최적 Temperature는 변수 특성과 질문 유형에 따라 달라질 수 있다.

### 2.3 Chain-of-Thought(CoT) 추론

Wei et al.(2022)이 제안한 CoT 프롬프팅은 LLM이 답변 전 중간 추론 과정을 생성하도록 유도하여, 복잡한 문제 해결 능력을 향상시킨다. Dillion et al.(2023)은 이를 설문조사 맥락에 적용하여, LLM이 "왜" 특정 응답을 선택하는지 설명하도록 유도했다.

CoT의 이론적 효과:
- 페르소나 특성과 질문 내용의 깊은 고려
- 극단적 응답 회피 경향 감소
- 맥락적으로 일관된 응답 생성

그러나 CoT가 모든 유형의 질문에 효과적인지, 오히려 과도한 합리화를 유발하지 않는지는 실증적 검증이 필요하다.

### 2.4 프롬프트 엔지니어링

Ornstein et al.(2024)은 프롬프트 구조가 LLM 응답 품질에 미치는 영향을 체계적으로 분석했다. 핵심 발견:
- 구체적 맥락 제공이 추상적 지시보다 효과적
- 페르소나 정보의 상세도가 응답 품질과 정적 상관
- 명시적 지시("솔직하게 답변하세요")가 암묵적 기대보다 효과적

### 2.5 모델 발전과 성능 향상

OpenAI의 공식 벤치마크에 따르면, GPT-3 → GPT-4 → GPT-4o → GPT-5 시리즈로 발전하며 다양한 과제에서 성능이 향상되었다. 그러나:
- 사회조사 시뮬레이션에 특화된 벤치마크는 부재
- 문화적 맥락 이해 능력의 발전 정도는 미검증
- 한국어 능력 향상 정도는 별도 검증 필요

### 2.6 문화적 맥락과 토착 LLM

LLM의 성능은 학습 데이터의 언어적, 문화적 구성에 크게 의존한다. 주요 LLM(GPT, Claude, Gemini 등)은 영어 중심의 서구 데이터로 학습되어, 비서구권 맥락에서 성능 저하가 보고되었다 (Cao et al., 2023; Durmus et al., 2024).

**토착 LLM의 부상**:
각국은 자국어와 문화에 특화된 LLM 개발에 투자하고 있다:
- **한국**: CLOVA (네이버), HyperCLOVA X, KoGPT (카카오)
- **중국**: Ernie (바이두), Tongyi Qianwen (알리바바)
- **일본**: Japanese StableLM, ELYZA

**토착 LLM의 이론적 장점**:
1. **언어적 정교함**: 해당 언어의 문법, 어휘, 관용표현에 대한 깊은 이해
2. **문화적 맥락**: 사회규범, 역사적 맥락, 정치적 뉘앙스 학습
3. **지역 데이터 접근**: 해당 국가의 뉴스, 문서, 온라인 담론 집중 학습

**CLOVA HCX-007의 특징**:
네이버의 HCX-007(HyperCLOVA X)은 한국어에 특화된 대규모 언어모델로:
- 한국어 웹 데이터, 뉴스, 문서 집중 학습
- 한국 사회문화적 맥락 이해
- Thinking 기능을 통한 추론 능력 강화

그러나 토착 LLM이 실제로 해당 문화권의 사회조사 시뮬레이션에서 우수한 성능을 보이는지에 대한 실증 연구는 전무한 상태이다. 본 연구는 이 공백을 채우는 첫 번째 시도이다.

### 2.7 연구 공백과 본 연구의 위치

기존 연구의 한계:
1. **개별 검증**: 각 방법론이 독립적으로 검증되어 상대적 효과 비교 불가
2. **일관된 벤치마크 부재**: 연구마다 다른 데이터셋 사용으로 비교 어려움
3. **비서구권 맥락 부족**: 영어권 중심 연구로 일반화 한계
4. **변수 특성과의 상호작용 미분석**: 어떤 변수에서 어떤 방법론이 효과적인지 불명확

본 연구는 이러한 공백을 채우기 위해:
- 동일한 벤치마크(KGSS 2023)를 사용한 5가지 방법론 통합 검증
- 한국 맥락에서의 효과성 검증
- 변수 특성에 따른 방법론 효과 차이 분석

---

## 3. Research Framework

### 3.1 통합 검증 프레임워크

본 연구는 다음과 같은 통합 검증 프레임워크를 채택한다:

```
┌─────────────────────────────────────────────────────────────────┐
│                    벤치마크: KGSS 2023                          │
│                    (7개 변수, 실제 분포)                         │
└─────────────────────────────────────────────────────────────────┘
                              ▼
┌─────────────────────────────────────────────────────────────────┐
│ 실험 1: 기본 시뮬레이션    │ 페르소나 기반 기본 성능 측정        │
├─────────────────────────────────────────────────────────────────┤
│ 실험 2: Temperature 최적화  │ T=0.3, 0.5, 0.7, 0.9, 1.1 비교    │
├─────────────────────────────────────────────────────────────────┤
│ 실험 3: Chain-of-Thought   │ Baseline vs CoT 비교              │
├─────────────────────────────────────────────────────────────────┤
│ 실험 4: 프롬프트 엔지니어링 │ 3가지 전략 비교                    │
├─────────────────────────────────────────────────────────────────┤
│ 실험 5: 모델 비교          │ GPT-4o-mini vs GPT-5.2                  │
├─────────────────────────────────────────────────────────────────┤
│ 실험 6: 문화적 맥락        │ GPT-5.2 vs CLOVA HCX-007 (토착 LLM)     │
└─────────────────────────────────────────────────────────────────┘
                              ▼
┌─────────────────────────────────────────────────────────────────┐
│              교차 분석: 방법론 × 변수 특성 × 문화적 맥락          │
│              (정치적 민감도, 사회적 바람직성, 토착 LLM 효과)      │
└─────────────────────────────────────────────────────────────────┘
```

### 3.2 벤치마크 데이터: KGSS 2023

한국종합사회조사(Korean General Social Survey, KGSS) 2023을 벤치마크로 선정하였다. KGSS는:
- 성균관대학교 서베이리서치센터 주관
- 전국 규모 층화다단계집락표집
- 표본 크기: 1,503명, 응답률: 43.2%
- 2003년 이후 연례 실시

### 3.3 분석 변수

7개 변수를 선정하여 다양한 특성을 포괄하였다:

| 변수명 | 내용 | 척도 | 정치적 민감도 | 사회적 바람직성 |
|--------|------|------|--------------|----------------|
| SATFIN | 가계 경제 상태 만족도 | 1-5 | 낮음 | 낮음 |
| CONFINAN | 금융기관 신뢰 | 1-3 | 낮음 | 낮음 |
| CONLEGIS | 국회 신뢰 | 1-3 | 중간 | 낮음 |
| PARTYLR | 정치 성향 (진보-보수) | 1-5 | 높음 | 낮음 |
| NORTHWHO | 북한에 대한 인식 | 1-4 | 높음 | 높음 |
| UNIFI | 남북통일 필요성 | 1-4 | 중간 | 높음 |
| KRPROUD | 한국인 자부심 | 1-4 | 낮음 | 높음 |

### 3.4 평가 지표

**Jensen-Shannon(JS) Divergence**: 두 확률 분포 간 대칭적 거리 측정
```
JS(P||Q) = 0.5 * KL(P||M) + 0.5 * KL(Q||M), M = 0.5 * (P + Q)
```
- 범위: 0(완전 일치) ~ 1(완전 불일치)
- 해석 기준: <0.1 우수, 0.1-0.3 양호, 0.3-0.5 보통, >0.5 불량

**Kolmogorov-Smirnov(KS) Test**: 분포 동일성 검정
- 귀무가설: 두 분포가 동일
- p < 0.05: 통계적으로 유의한 차이

**개선율**: 방법론 적용 전후 JS Divergence 변화율
```
개선율 = (JS_baseline - JS_method) / JS_baseline × 100%
```

### 3.5 실험 공통 설정

**페르소나 설계**: KGSS 2023 인구학적 분포 반영 100개 층화 페르소나
- 층화변수: 연령(5), 성별(2), 학력(3), 지역(4), 직업(8)
- 각 페르소나에 고유 ID(P001-P100) 부여

**기본 모델**: OpenAI GPT-4o (실험 5는 GPT-5.2 추가)

**기본 Temperature**: 0.7 (실험 2에서 변동)

**샘플 크기**: n=100 (프롬프트 실험 탐색은 n=5)

**실험별 Baseline 정의**: 각 실험의 "Baseline"은 해당 실험 내 통제 조건을 의미하며, 실험 간 절대적 동일성을 보장하지 않는다. 이는 각 실험이 독립적으로 설계되어 서로 다른 시점, 프롬프트 구조, API 버전에서 수행되었기 때문이다. 방법론 간 효과 비교는 Section 9의 교차 분석에서 통합적으로 다룬다.

---

## 4. Experiment 1: 기본 시뮬레이션 능력 검증

### 4.1 실험 목적

**검증 대상 주장**: "LLM에 인구학적 페르소나를 제공하면 해당 인구집단의 응답 분포를 재현할 수 있다" (Argyle et al., 2023)

### 4.2 실험 방법

**프롬프트 구조**:
```
시스템: 당신은 설문조사 응답자입니다. 질문에 숫자로만 답변하세요.

사용자: 당신은 다음과 같은 특성을 가진 한국인입니다:
- 나이: [연령대]
- 성별: [성별]
- 학력: [학력]
- 거주 지역: [지역]
- 직업: [직업]

질문: [KGSS 원문 질문]
응답 선택지: [척도 설명]
```

**설정**: GPT-4o, Temperature=0.7, n=100 페르소나

### 4.3 결과

#### 4.3.1 전체 정확도

| 변수 | JS Divergence | KS Statistic | p-value | 판정 |
|------|---------------|--------------|---------|------|
| SATFIN | 0.398 | 0.512 | <0.001 | ❌ 유의한 차이 |
| CONFINAN | 0.447 | 0.667 | <0.001 | ❌ 유의한 차이 |
| CONLEGIS | 0.440 | 0.667 | <0.001 | ❌ 유의한 차이 |
| PARTYLR | 0.585 | 0.378 | <0.001 | ❌ 유의한 차이 |
| NORTHWHO | 0.324 | 0.423 | <0.001 | ❌ 유의한 차이 |
| UNIFI | 0.314 | 0.398 | <0.001 | ❌ 유의한 차이 |
| KRPROUD | 0.272 | 0.356 | <0.001 | ❌ 유의한 차이 |
| **평균** | **0.397** | **0.486** | - | - |

**결과 요약**: 7개 변수 모두에서 KGSS 실제 분포와 통계적으로 유의한 차이가 발견되었다. 평균 JS Divergence 0.397은 "보통" 수준으로, Argyle et al.(2023)이 보고한 미국 GSS 결과(평균 상관 0.85)와 상당한 차이를 보인다.

#### 4.3.2 체계적 편향 패턴

**패턴 1: 범주 붕괴 (Category Collapse)**
- NORTHWHO: 100% "협력 대상(2)" 응답 (KGSS: 분포 다양)
- CONFINAN: 100% "다소 신뢰(2)" 응답
- CONLEGIS: 100% "거의 신뢰 안함(3)" 응답

**패턴 2: 중앙화/극단값 회피 (Centralization)**
- SATFIN: 3점(보통) 68% 집중, 1점·5점 0%
- PARTYLR: 5점(중도) 72% 집중, 극단값(0-2, 8-10) 현저히 저조

**패턴 3: 긍정 편향 (Positivity Bias)**
- KRPROUD: "매우 자랑스럽다(1)" 58% (KGSS: 32%)
- UNIFI: "매우 필요(1)" 45% (KGSS: 28%)
- 부정적 응답(3, 4) 거의 0%

**패턴 4: 부정 범주 누락 (Negativity Omission)**
- UNIFI: "필요 없다(3-4)" 0% (KGSS: 48.6%)
- KRPROUD: 부정 응답(3-4) 0% (KGSS: 11.8%)

### 4.4 실험 1 결론

**주장 검증 결과**: ❌ 부분적으로 기각

인구학적 페르소나 기반 시뮬레이션은 KGSS 2023 분포를 정확히 재현하지 못했다. 주요 발견:

1. **전반적 정확도 부족**: 평균 JS=0.397로 "보통" 수준
2. **체계적 편향 존재**: 범주 붕괴, 중앙화, 긍정 편향, 부정 누락
3. **변수별 차이**: KRPROUD/UNIFI (JS=0.27-0.31) > CONFINAN/PARTYLR (JS=0.45-0.59)
4. **미국 결과와의 괴리**: Argyle et al.(2023)의 높은 상관계수와 불일치

이러한 결과는 후속 방법론적 개선 실험의 필요성을 시사한다.

---

## 5. Experiment 2: Temperature 최적화 검증

### 5.1 실험 목적

**검증 대상 주장**: "Temperature 파라미터 조정으로 응답 분포를 최적화할 수 있다"

### 5.2 실험 방법

**Temperature 조건**: T = 0.3, 0.5, 0.7, 0.9, 1.1
**대상 변수**: SATFIN, CONFINAN, CONLEGIS, PARTYLR (4개)
**설정**: GPT-4o, n=100 페르소나, 각 조건별 독립 실행

### 5.3 결과

#### 5.3.1 변수별 최적 Temperature

| 변수 | 기본(T=0.7) JS | 최적 Temperature | 최적 JS | 개선율 |
|------|---------------|-----------------|---------|--------|
| SATFIN | 0.398 | **T=1.1** | 0.224 | **43.7% 개선** |
| PARTYLR | 0.585 | **T=0.7** | 0.502 | **14.1% 개선** |
| CONFINAN | 0.447 | T=0.3 | 0.447 | 0% (무효과) |
| CONLEGIS | 0.440 | T=0.3 | 0.440 | 0% (무효과) |

#### 5.3.2 Temperature 효과 패턴

**효과적인 경우 (SATFIN, PARTYLR)**:
```
SATFIN: T=0.3(0.505) → T=0.7(0.398) → T=1.1(0.224)
        높은 Temperature에서 응답 다양성 증가 → 분포 일치도 향상

PARTYLR: T=0.3(0.612) → T=0.7(0.502) → T=1.1(0.558)
         중간 Temperature(T=0.7)가 최적
         너무 높으면 오히려 악화
```

**무효과인 경우 (CONFINAN, CONLEGIS)**:
```
CONFINAN: 모든 Temperature에서 JS ≈ 0.447
          단일 응답 집중 패턴 불변
          Temperature 조정으로 범주 붕괴 해결 불가

CONLEGIS: 모든 Temperature에서 JS ≈ 0.440
          구조적 편향이 파라미터보다 강력
```

### 5.4 실험 2 결론

**주장 검증 결과**: ⚠️ 부분적으로 지지

Temperature 최적화는 일부 변수에서 효과적이나 보편적 해결책이 아니다:

| 발견 | 내용 |
|------|------|
| ✅ 효과적 | 연속형 척도 변수(SATFIN: 5점, PARTYLR: 11점)에서 개선 |
| ✅ 최대 개선 | SATFIN에서 43.7% 개선 달성 |
| ❌ 무효과 | 범주형 신뢰 변수(CONFINAN, CONLEGIS)에서 무효과 |
| ⚠️ 변수별 최적값 상이 | SATFIN(T=1.1), PARTYLR(T=0.7) |

**실무 권고**: Temperature 최적화는 연속형 척도 변수에서 시도할 가치가 있으나, 범주형 신뢰 변수에서는 효과를 기대하기 어렵다. 변수별 파일럿 테스트가 필수적이다.

---

## 6. Experiment 3: Chain-of-Thought(CoT) 검증

### 6.1 실험 목적

**검증 대상 주장**: "중간 추론 과정(CoT)이 응답 품질을 향상시킨다" (Dillion et al., 2023)

### 6.2 실험 방법

**조건 1 - Baseline**:
```
질문에 숫자로만 답변하세요.
```

**조건 2 - Chain-of-Thought**:
```
먼저 귀하의 특성을 고려하여 이 질문에 대해 어떻게 생각하는지 설명하고,
그 다음 최종 응답을 숫자로 제시하세요.
```

**대상 변수**: CONFINAN, CONLEGIS (신뢰 변수)
**설정**: GPT-4o, Temperature=0.7, n=100 페르소나

### 6.3 결과

| 변수 | Baseline JS | CoT JS | 변화 | 판정 |
|------|-------------|--------|------|------|
| CONFINAN | 0.0283 | 0.1065 | **+276.9%** | ❌ 현저히 악화 |
| CONLEGIS | 0.2268 | 0.2211 | **+2.5%** | ✅ 소폭 개선 |

#### 6.3.1 CONFINAN 악화 분석

Baseline에서 CONFINAN은 예외적으로 낮은 JS(0.0283)를 보였다. 이는 LLM 응답 분포가 우연히 KGSS와 유사했기 때문이다. 그러나 CoT 적용 시:

- 추론 과정에서 "신뢰도를 비판적으로 평가해야 한다"는 방향으로 편향
- "다소 신뢰(2)" → "거의 신뢰 안함(3)"으로 응답 이동
- 결과적으로 KGSS 분포와 괴리 증가

**CoT 추론 예시**:
```
"금융기관에 대해 생각해보면... 최근 금융 위기와 부정적 뉴스들을 고려할 때...
완전히 신뢰하기 어렵다고 생각합니다. 응답: 3"
```

#### 6.3.2 CONLEGIS 소폭 개선 분석

CONLEGIS는 CoT 적용으로 2.5% 개선되었으나, 통계적으로 유의미한 수준은 아니다. CoT가 응답 분포를 약간 다양화했으나, 기본적인 "불신" 편향은 유지되었다.

### 6.4 실험 3 결론

**주장 검증 결과**: ❌ 기각

Chain-of-Thought는 설문조사 맥락에서 일관된 개선 효과를 보이지 않았다:

| 발견 | 내용 |
|------|------|
| ❌ 비일관적 | 한 변수 악화, 한 변수 소폭 개선 |
| ❌ 과도한 합리화 | CoT가 오히려 편향을 강화하는 경우 발생 |
| ⚠️ 맥락 의존적 | 변수 특성에 따라 효과 상이 |
| ⚠️ 비용 증가 | 토큰 사용량 3-5배 증가 |

**이론적 해석**: CoT는 복잡한 추론 문제(수학, 논리)에서 효과적이나, 설문조사 응답은 "정답"이 없는 태도/의견 표명이다. 추론 과정이 오히려 LLM의 내재된 편향(예: 비판적 사고 선호)을 표면화시킬 수 있다.

---

## 7. Experiment 4: 프롬프트 엔지니어링 검증

### 7.1 실험 목적

**검증 대상 주장**: "프롬프트 최적화로 응답 정확도를 향상시킬 수 있다" (Ornstein et al., 2024)

### 7.2 실험 방법

**3가지 프롬프트 전략**:

| 전략 | 프롬프트 |
|------|----------|
| Baseline | "질문에 1-5 중 하나의 숫자로만 답변하세요." |
| Persona-reinforced | "당신의 특성을 고려하여 솔직하게 답변하세요." |
| Extreme-allowed | "극단적인 의견도 괜찮습니다. 솔직하게 답변하세요." |

**설정**: GPT-4o, Temperature=0.7, 7개 변수, n=100 페르소나

### 7.3 결과

#### 7.3.1 전체 성능 비교

| 전략 | 평균 JS | 중립 응답 비율 | 응답 분산 | 평가 |
|------|---------|---------------|----------|------|
| Baseline | 0.472 | 97.1% | 0.029 | 기준선 |
| Persona-reinforced | 0.386 | 74.3% | 0.286 | 18.2% 개선 |
| **Extreme-allowed** | **0.358** | **57.1%** | **0.214** | **24.2% 개선** |

#### 7.3.2 변수별 상세 결과

| 변수 | Baseline | Persona-reinforced | Extreme-allowed | 최우수 전략 |
|------|----------|-------------------|-----------------|------------|
| SATFIN | 0.339 | 0.255 | **0.255** | Extreme/Persona |
| CONFINAN | 0.581 | 0.581 | **0.246** | Extreme |
| CONLEGIS | 0.590 | 0.590 | 0.590 | 무차별 |
| PARTYLR | 0.315 | **0.268** | 0.356 | Persona |
| NORTHWHO | 0.559 | **0.367** | **0.206** | Extreme |
| UNIFI | 0.527 | 0.527 | 0.527 | 무차별 |
| KRPROUD | 0.395 | **0.112** | **0.328** | Persona |

#### 7.3.3 전략별 효과 패턴

**Extreme-allowed 전략**:
- 극단 응답 허용 명시 → 중앙화 편향 완화
- 특히 신뢰 변수(CONFINAN)와 태도 변수(NORTHWHO)에서 효과적
- 응답 분포 다양화에 기여

**Persona-reinforced 전략**:
- 페르소나 특성 강조 → 개인 차이 반영 증가
- 정치 성향(PARTYLR)과 정체성(KRPROUD)에서 효과적
- 그러나 일부 변수에서 무효과

**Baseline 전략**:
- 중립적 지시 → 안전한 중앙 응답 경향
- 중앙화 편향 최대화
- 분포 다양성 최소

### 7.4 실험 4 결론

**주장 검증 결과**: ✅ 지지

프롬프트 엔지니어링은 효과적인 개선 전략이다:

| 발견 | 내용 |
|------|------|
| ✅ 전반적 효과 | Extreme-allowed 전략 평균 24.2% 개선 |
| ✅ 중앙화 완화 | 중립 응답 비율 97.1% → 57.1% 감소 |
| ✅ 다양성 증가 | 응답 분산 0.029 → 0.214 증가 |
| ⚠️ 변수별 차이 | 최적 전략이 변수에 따라 상이 |
| ⚠️ 한계 존재 | CONLEGIS, UNIFI는 어떤 전략도 무효과 |

**실무 권고**:
- 기본적으로 "Extreme-allowed" 전략 권장
- 정치 성향/정체성 변수는 "Persona-reinforced" 고려
- 신뢰 변수는 프롬프트 외 다른 접근법 필요

---

## 8. Experiment 5: 모델 발전 효과 검증

### 8.1 실험 목적

**검증 대상 주장**: "최신 모델일수록 시뮬레이션 정확도가 향상된다"

### 8.2 실험 방법

**비교 모델**:
- GPT-4o-mini (2024년 출시)
- GPT-5.2 (2025년 출시)

**대상 변수**: SATFIN, PARTYLR, NORTHWHO, UNIFI (4개)
**설정**: Temperature=0.7, n=100 페르소나

### 8.3 결과

#### 8.3.1 모델별 성능 비교

| 변수 | GPT-4o-mini JS | GPT-5.2 JS | 개선율 |
|------|----------------|------------|--------|
| SATFIN | 0.398 | 0.312 | **21.6%** |
| PARTYLR | 0.585 | 0.467 | **20.2%** |
| NORTHWHO | 0.456 | 0.259 | **43.3%** |
| UNIFI | 0.345 | 0.299 | **13.3%** |
| **평균** | **0.446** | **0.334** | **22.6%** |

#### 8.3.2 개선 패턴 분석

**NORTHWHO (최대 개선: 43.3%)**:
- GPT-5.2가 한국의 대북 인식 스펙트럼을 더 정확히 이해
- "협력 대상" 집중에서 4개 범주로 분산
- 정치적 맥락 이해 능력 향상 시사

**SATFIN (21.6% 개선)**:
- 경제 만족도 분포 다양화
- 중앙화 편향 감소
- 그러나 여전히 실제 분포와 괴리

**PARTYLR (20.2% 개선)**:
- 정치 성향 분포 약간 개선
- 극단값 표현 능력 여전히 제한적

### 8.4 실험 5 결론

**주장 검증 결과**: ✅ 지지

모델 발전은 일관된 성능 향상을 가져온다:

| 발견 | 내용 |
|------|------|
| ✅ 일관된 개선 | 4개 변수 모두에서 GPT-5.2 우수 |
| ✅ 평균 22.6% | 유의미한 성능 향상 |
| ✅ 맥락 이해 향상 | 특히 한국 정치/사회 맥락 이해 개선 |
| ⚠️ 절대적 한계 | 최선 결과(JS=0.259)도 "양호" 수준 미달 |
| ⚠️ 비용 증가 | GPT-5.2 API 비용 GPT-4o 대비 2-3배 |

**실무 권고**:
- 정확도가 중요한 경우 최신 모델 권장
- 비용-효과 분석 후 모델 선택
- 최신 모델도 파일럿 검증 필수

---

## 9. Experiment 6: 문화적 맥락과 토착 LLM 비교

### 9.1 실험 목적

**검증 대상 주장**: "자국 문화 맥락을 학습한 토착 LLM이 서구 LLM보다 해당 사회의 여론조사 시뮬레이션에서 우수한 성능을 보인다"

이 실험은 실리콘 샘플링의 문화적 한계를 탐구하고, 비서구권 사회과학 연구에서 토착 LLM의 필요성을 검증한다.

### 9.2 실험 방법

**비교 모델**:
- GPT-5.2 (OpenAI, 서구권 개발, 범용 모델)
- CLOVA HCX-007 (Naver, 한국 개발, 한국어 특화)

**CLOVA HCX-007 특징**:
- 한국어 말뭉치 중심 사전학습
- 한국 문화, 사회, 역사적 맥락 내재화
- "Thinking" 기능으로 추론 과정 명시화 (short 모드 사용)

**대상 변수**: CONFINAN, CONLEGIS, KRPROUD, NORTHWHO, UNIFI, PARTYLR (6개)
**설정**: Temperature=0.7, n=100 페르소나, CLOVA thinking=short/medium

### 9.3 결과

#### 9.3.1 모델별 성능 비교 (JS Divergence)

| 변수 | GPT-5.2 JS | CLOVA JS | CLOVA 우위 | 개선율 |
|------|------------|----------|-----------|--------|
| CONFINAN | 0.0979 | 0.0622 | ✅ | **36.5%** |
| CONLEGIS | 0.3608 | 0.0825 | ✅ | **77.1%** |
| KRPROUD | 0.1409 | 0.1338 | ✅ | **5.0%** |
| NORTHWHO | 0.3773 | 0.0841 | ✅ | **77.7%** |
| UNIFI | 0.2681 | 0.1150 | ✅ | **57.1%** |
| PARTYLR | 0.1060 | 0.0653 | ✅ | **38.4%** |
| **평균** | **0.2252** | **0.0905** | ✅ | **59.8%** |

*주: 낮은 JS 값 = 더 정확한 시뮬레이션*

#### 9.3.2 통계적 유의성 검정 (KS Test)

Kolmogorov-Smirnov 검정을 통해 LLM 시뮬레이션 분포와 KGSS 실제 분포 간의 통계적 차이를 검정하였다 (유의수준 α=0.05).

| 변수 | GPT-5.2 D | GPT-5.2 p | 판정 | CLOVA D | CLOVA p | 판정 |
|------|-----------|-----------|------|---------|---------|------|
| CONFINAN | 0.804 | <0.001 | ❌ 유의한 차이 | 0.167 | 0.103 | ✅ **유의한 차이 없음** |
| CONLEGIS | 0.663 | <0.001 | ❌ 유의한 차이 | 0.323 | <0.001 | ❌ 유의한 차이 |
| KRPROUD | 0.186 | 0.056 | ⚠️ 경계선 | 0.486 | <0.001 | ❌ 유의한 차이 |
| NORTHWHO | 0.702 | <0.001 | ❌ 유의한 차이 | 0.238 | 0.006 | ❌ 유의한 차이 |
| UNIFI | 0.490 | <0.001 | ❌ 유의한 차이 | 0.340 | <0.001 | ❌ 유의한 차이 |
| PARTYLR | 0.957 | <0.001 | ❌ 유의한 차이 | 0.251 | 0.004 | ❌ 유의한 차이 |

*D: Kolmogorov-Smirnov 통계량, p: p-value*

**핵심 발견**:

1. **CLOVA의 CONFINAN 재현 성공**: CLOVA의 금융기관 신뢰도(CONFINAN) 시뮬레이션은 KGSS 실제 분포와 **통계적으로 유의한 차이가 없다** (D=0.167, p=0.103). 이는 토착 LLM이 해당 문화권의 응답 분포를 성공적으로 재현할 수 있음을 의미한다.

2. **GPT-5.2의 KRPROUD 경계선 결과**: 흥미롭게도 GPT-5.2의 국민 자부심(KRPROUD) 시뮬레이션은 경계선 수준의 유의성을 보인다 (D=0.186, p=0.056). 이는 보편적 감정(자부심)의 경우 서구 LLM도 비교적 양호한 시뮬레이션이 가능함을 시사한다.

3. **문화특수적 vs 보편적 변수**: CLOVA는 문화특수적 변수(금융기관 신뢰)에서 재현에 성공한 반면, GPT-5.2는 보편적 감정 변수(자부심)에서 경계선 결과를 보였다. 이는 변수의 문화적 특수성이 LLM 선택에 중요한 기준이 될 수 있음을 시사한다.

#### 9.3.3 변수별 분석

**CONLEGIS (최대 개선: 77.1%)**:
- 국회 신뢰도 시뮬레이션에서 극적인 차이
- GPT-5.2: 전혀 신뢰하지 않음(0%), 별로 신뢰하지 않음(0%)으로 극단적 편향
- CLOVA: 실제 분포에 근접한 다양한 응답 생성
- 한국 정치 불신 문화에 대한 이해 차이 시사

**CONFINAN (36.5% 개선)**:
- 금융기관 신뢰도에서 CLOVA 우위
- GPT-5.2: 3점(78%), 4점(22%)으로 제한적 분포
- CLOVA: 2점(78%), 3점(22%)으로 실제 분포에 근접
- 한국인의 금융기관 인식 맥락 반영

**KRPROUD (5.0% 개선)**:
- 국민 자부심은 두 모델 모두 비교적 양호
- GPT-5.2: 범주 2에 100% 집중
- CLOVA: 범주 1(5%), 2(33%), 3(62%)로 분산
- CLOVA가 더 다양한 자부심 수준 표현

**NORTHWHO (77.7% 개선)**:
- 북한 인식에서 극적인 차이
- GPT-5.2: 범주 2(협력)에 98% 집중, 단일 관점 고착
- CLOVA: 범주 2(4%), 3(78%), 4(18%)로 다양한 분포
- 한국인의 복잡한 대북 인식 스펙트럼 반영

**UNIFI (57.1% 개선)**:
- 통일 인식에서 CLOVA 우위
- GPT-5.2: 범주 2에 100% 집중
- CLOVA: 1(2%), 2(15%), 3(82%), 4(1%)로 다양화
- 통일에 대한 한국인의 복합적 태도 반영

**PARTYLR (38.4% 개선)**:
- 정치 성향 시뮬레이션에서 개선
- GPT-5.2: 5-8점대 집중 (우편향)
- CLOVA: 2-5점대로 더 넓은 분포
- 한국 정치 지형에 대한 이해 차이

### 9.4 발견 및 해석

#### 9.4.1 핵심 발견

| 발견 | 내용 | 함의 |
|------|------|------|
| ✅ CLOVA 전체 우위 | 6개 변수 전체에서 CLOVA 우수 | 문화적 맥락 중요성 입증 |
| ✅ 정치/사회 변수 | CONLEGIS(77%), NORTHWHO(78%)에서 극적 개선 | 정치 문화 이해 차이 극명 |
| ✅ 분포 다양성 | CLOVA가 더 다양한 응답 분포 생성 | GPT의 집중화 편향 극복 |
| ✅ 평균 59.8% 개선 | 전 변수 일관된 개선 | 토착 LLM 효과 강건 |
| ⚠️ 성능 격차 가변 | 변수별 5%-78% 격차 | 문화 민감도에 따라 차이 |

#### 9.4.2 문화적 맥락의 역할

**가설**: 토착 LLM의 우위는 "문화적 맥락 인코딩"에서 기인한다.

1. **정치 불신 문화**: 한국의 국회 불신은 역사적, 문화적 맥락에 깊이 뿌리박음
   - GPT-5.2는 이 맥락 부재로 중립적/긍정적 편향
   - CLOVA는 한국 뉴스, 여론 데이터에서 이 패턴 학습

2. **금융기관 인식**: IMF 위기, 카드 대란 등 역사적 경험 반영
   - 한국인의 금융기관 경계심 CLOVA에 내재화

3. **민족 정체성**: 국민 자부심의 복잡한 스펙트럼
   - 두 모델 모두 비교적 양호하나 CLOVA가 더 섬세한 분포

### 9.5 실험 6 결론

**주장 검증 결과**: ✅ 강하게 지지

| 결론 | 상세 |
|------|------|
| ✅ 토착 LLM 압도적 우위 | 6/6 변수에서 CLOVA 우수 (평균 59.8% 개선) |
| ✅ 정치/사회 맥락 | NORTHWHO(78%), CONLEGIS(77%)에서 극적 격차 |
| ✅ 분포 다양성 | GPT의 단일범주 집중화 vs CLOVA의 다양한 분포 |
| ✅ 학술적 함의 | 비서구권 사회과학 연구에서 토착 LLM 필수 |
| ⚠️ 범용성 vs 특수성 | 일부 변수(KRPROUD: 5%)에서 격차 작음 |

**연구 함의**:

1. **실리콘 샘플링의 문화적 한계**: 서구 LLM 기반 실리콘 샘플링은 비서구권에서 구조적 한계
2. **토착 LLM 개발 필요성**: 각국 문화 맥락을 반영한 LLM 개발이 사회과학 연구에 필수
3. **방법론적 권고**: 비서구권 실리콘 샘플링 연구 시 해당 문화권 LLM 우선 고려
4. **미래 연구 방향**: 다문화 LLM 비교 연구, 문화적 편향 정량화 프레임워크 개발

---

## 10. Cross-Experiment Analysis: 방법론 통합 분석

### 10.1 방법론별 효과성 비교

| 방법론 | 평균 개선율 | 효과 범위 | 비용 영향 | 종합 평가 |
|--------|------------|----------|----------|----------|
| **프롬프트 엔지니어링** | 24.2% | 보통 | 낮음 | ★★★★☆ |
| **모델 업그레이드** | 22.6% | 높음 | 높음 | ★★★★☆ |
| **Temperature 최적화** | 14.5% | 좁음 | 없음 | ★★★☆☆ |
| **Chain-of-Thought** | 비일관 | 낮음 | 중간 | ★☆☆☆☆ |

### 10.2 변수 특성별 최적 방법론

| 변수 유형 | 특성 | 최적 방법론 | 예시 변수 |
|-----------|------|------------|----------|
| 연속형 척도 | 다점 Likert | Temperature + Extreme-allowed | SATFIN, PARTYLR |
| 범주형 신뢰 | 3점 척도 | 효과적 방법 없음 | CONFINAN, CONLEGIS |
| 정치적 민감 | 높은 민감도 | 최신 모델 + Persona-reinforced | NORTHWHO |
| 사회적 바람직성 | 긍정 편향 유발 | Extreme-allowed | KRPROUD, UNIFI |

### 10.3 방법론 조합 권장

**Tier 1 (권장 조합)**:
```
최신 모델(GPT-5+) + Extreme-allowed 프롬프트 + 변수별 Temperature 최적화
예상 개선: 35-50%
적용 대상: 연속형 척도, 태도 변수
```

**Tier 2 (조건부 권장)**:
```
GPT-4o + Persona-reinforced 프롬프트
예상 개선: 15-25%
적용 대상: 정치 성향, 정체성 변수
```

**Tier 3 (비권장)**:
```
Chain-of-Thought
이유: 비일관적 효과, 비용 증가, 일부 악화 사례
```

### 10.4 실리콘 샘플링 방법론 한계

**구조적 한계**:
1. **범주형 신뢰 변수**: 어떤 방법론도 유의미한 개선 달성 실패
2. **사회적 바람직성**: 긍정 편향 완전 제거 불가
3. **문화적 맥락**: 한국어 학습 데이터 부족으로 인한 근본적 한계

**최선 결과의 한계**:
- 최적 조합 적용 시에도 평균 JS ≈ 0.25-0.30
- 통계적 검정에서 여전히 KGSS와 유의한 차이
- 전통적 조사 대체 수준 미달

---

## 11. Discussion

### 11.1 주요 발견 요약

본 연구는 실리콘 샘플링 분야에서 제안된 방법론의 효과성을 KGSS 2023을 벤치마크로 체계적으로 검증하였다. 주요 발견:

**Part I: 방법론 효과성 검증**
1. **기본 시뮬레이션**: 인구학적 페르소나만으로는 정확한 분포 재현 불가 (평균 JS=0.397)
2. **Temperature 최적화**: 연속형 변수에서 효과적 (최대 43.7% 개선), 범주형 신뢰 변수 무효과
3. **Chain-of-Thought**: 비일관적 결과, 권장하지 않음
4. **프롬프트 엔지니어링**: 가장 비용-효과적인 방법 (Extreme-allowed 전략 24.2% 개선)

**Part II: 모델 발전과 문화적 맥락**
5. **모델 발전**: 일관된 개선 효과 (GPT-5.2가 GPT-4o-mini 대비 22.6% 개선) → LLM 발전이 실리콘 샘플링 가능성 제고
6. **문화적 맥락**: 토착 LLM(CLOVA)이 서구 LLM(GPT-5.2)을 6개 변수 전체에서 압도 (평균 59.8% 개선) → 비서구권 연구에서 토착 LLM 필수

### 11.2 이론적 함의

**Algorithmic Fidelity의 한계와 확장**:
Argyle et al.(2023)의 "algorithmic fidelity" 개념은 영어권 데이터에서 높은 정확도를 보였으나, 한국 맥락에서는 제한적이다. 그러나 본 연구는 이 한계가 **모델 선택**으로 극복될 수 있음을 보여준다:
- 서구 LLM(GPT-5.2): 한국 맥락에서 체계적 편향 (6개 변수 중 5개에서 유의한 차이)
- 토착 LLM(CLOVA): 한국 문화/정치 맥락 내재화로 59.8% 개선
- **핵심 발견**: CLOVA의 CONFINAN(금융기관 신뢰) 시뮬레이션은 KGSS 실제 분포와 **통계적으로 유의한 차이가 없음** (KS test: D=0.167, p=0.103). 이는 토착 LLM이 특정 변수에서 실제 조사 분포를 재현할 수 있음을 실증한다.

**실리콘 샘플링의 미래 가능성**:
GPT-4o-mini → GPT-5.2 비교(22.6% 개선)는 LLM 발전이 실리콘 샘플링의 실현 가능성을 높인다는 것을 시사한다. 향후 모델 발전으로 현재의 한계가 점진적으로 극복될 수 있다.

**편향의 다층성과 해결책**:
LLM 편향은 단일 원인이 아닌 다층적 구조를 가진다:
- **학습 데이터 편향**: 영어/서구 중심 데이터 → **토착 LLM으로 해결 가능**
- **RLHF 편향**: "안전한" 응답 선호 → 프롬프트 엔지니어링으로 완화
- **구조적 편향**: 확률적 샘플링의 본질적 한계 → 근본적 한계

**문화적 맥락 인코딩 가설**:
CLOVA의 우위는 "문화적 맥락 인코딩"에서 기인한다. 특히 정치적 변수(국회 신뢰, 대북 인식)에서 격차가 극대화(77-78%)된 것은 이러한 변수가 문화-역사적 맥락 없이는 정확히 시뮬레이션될 수 없음을 시사한다.

### 11.3 실무적 함의

**사용 가이드라인**:

| 상황 | 권고 |
|------|------|
| 예비조사/탐색 | 조건부 사용 가능 (파일럿 검증 필수) |
| 본조사 대체 | 권장하지 않음 |
| 보조 자료 생성 | 주의하여 사용 가능 |
| 민감 변수 조사 | 토착 LLM 사용 시 조건부 가능 |
| 비서구권 조사 | **토착 LLM 필수** |

**비용-효과 분석**:
- 프롬프트 엔지니어링: 추가 비용 없음, 효과 있음 → 최우선 적용
- Temperature 최적화: 추가 비용 없음, 변수별 효과 → 파일럿 후 적용
- 모델 업그레이드: 비용 2-3배 증가, 일관된 효과 → 예산 허용 시 적용
- **토착 LLM 사용**: 비용 유사, 문화적 맥락 효과 극대화(59.8% 개선) → **비서구권 필수**
- CoT: 비용 3-5배 증가, 비일관적 → 비권장

### 11.4 연구 한계

1. **단일 벤치마크**: KGSS 2023만 사용, 다른 조사와의 일반화 검증 필요
2. **변수 제한**: 7개 변수만 분석, 더 다양한 변수 유형 검토 필요
3. **페르소나 설계**: 5개 인구학적 변수만 사용, 심리적 특성 미반영
4. **시점 한계**: 2025년 시점 모델 기준, 모델 발전에 따라 결과 변화 가능
5. **상호작용 미분석**: 방법론 간 상호작용 효과 심층 분석 부족

### 11.5 향후 연구 방향

1. **다국 토착 LLM 비교**: 한국(CLOVA), 일본(일본어 LLM), 중국(중국어 LLM) 등 각국 토착 LLM 간 비교
2. **문화적 편향 정량화 프레임워크**: LLM의 문화적 편향을 측정하는 표준화된 지표 개발
3. **종단 연구**: 모델 발전에 따른 정확도 변화 및 토착 LLM 격차 변화 추적
4. **하이브리드 방법론**: 토착 LLM + 소규모 실제 조사 결합
5. **변수 유형 확장**: 행동 변수, 지식 변수, 사실 확인 변수 포함
6. **최적 조합 연구**: 토착 LLM + 프롬프트 엔지니어링 + Temperature 최적화의 시너지 효과 분석

---

## 12. Conclusion

### 12.1 연구 요약

본 연구는 실리콘 샘플링의 효과성을 KGSS 2023을 벤치마크로 체계적으로 검증하였다. 두 가지 연구 축을 통해:
- **방법론 효과성**: 인구학적 페르소나, Temperature 최적화, Chain-of-Thought, 프롬프트 엔지니어링
- **모델 발전과 문화적 맥락**: GPT-4o-mini → GPT-5.2 발전 효과, GPT-5.2 vs CLOVA 문화적 맥락 효과

### 12.2 핵심 결론

**방법론별 효과성**:

| 방법론 | 검증 결과 | 권고 수준 |
|--------|----------|----------|
| **토착 LLM (CLOVA)** | ✅✅ 매우 효과적 | **비서구권 필수** |
| 프롬프트 엔지니어링 | ✅ 효과적 | 적극 권장 |
| 모델 업그레이드 | ✅ 효과적 | 비용 고려하여 권장 |
| Temperature 최적화 | ⚠️ 조건부 효과 | 변수별 파일럿 후 적용 |
| 인구학적 페르소나 | ⚠️ 기본적이나 불충분 | 필수이나 단독 불충분 |
| Chain-of-Thought | ❌ 비일관적 | 권장하지 않음 |

**전반적 평가**:
- 서구 LLM 기반 실리콘 샘플링은 비서구권에서 구조적 한계 존재
- **토착 LLM 사용 시 정확도 극적 개선 (평균 59.8%)**
- LLM 발전은 실리콘 샘플링 가능성 제고 (GPT-5.2가 22.6% 개선)
- 비서구권 연구에서는 토착 LLM 사용 필수, 서구권 연구도 문화적 맥락 고려 필요
- 모든 적용에서 파일럿 검증 필수

### 12.3 연구 기여

**학술적 기여**:
1. 실리콘 샘플링 방법론에 대한 최초의 체계적 통합 검증
2. 비서구권(한국) 맥락에서의 방법론 효과성 실증
3. 방법론 선택을 위한 증거 기반 프레임워크 제시
4. **모델 발전이 실리콘 샘플링 가능성을 높인다는 증거 제시**
5. **토착 LLM의 문화적 맥락 효과 실증 (최초 비교 연구)**

**실무적 기여**:
1. 변수 특성별 최적 방법론 가이드라인
2. 비용-효과 분석에 기반한 실용적 권고
3. 비서구권 연구자를 위한 토착 LLM 활용 가이드라인
4. 실리콘 샘플링 적용 시 문화적 맥락 고려 필요성 강조

### 12.4 맺음말

실리콘 샘플링은 사회조사 방법론의 혁신적 가능성을 제시한다. 본 연구는 두 가지 중요한 발견을 제시한다:

첫째, **LLM의 발전은 실리콘 샘플링의 미래 가능성을 높인다.** GPT-4o-mini에서 GPT-5.2로의 발전은 22.6%의 일관된 성능 향상을 가져왔으며, 이는 향후 모델 발전으로 현재의 한계가 점진적으로 극복될 수 있음을 시사한다.

둘째, **문화적 맥락은 실리콘 샘플링의 핵심 요소이다.** 한국 맥락에서 토착 LLM(CLOVA)이 서구 LLM(GPT-5.2)을 6개 변수 전체에서 압도(평균 59.8% 개선)한 것은 비서구권 사회과학 연구에서 문화적으로 맥락화된 LLM의 필수성을 강력히 시사한다. 특히 **CLOVA의 금융기관 신뢰도(CONFINAN) 시뮬레이션은 KGSS 실제 분포와 통계적으로 유의한 차이가 없음**이 확인되어(KS test: p=0.103), 토착 LLM이 특정 변수에서 실제 조사 분포를 재현할 수 있음을 실증하였다.

연구자들은 실리콘 샘플링 적용 시 반드시 해당 문화권의 토착 LLM을 우선 고려해야 하며, 서구 LLM에 기반한 연구 결과를 비서구권에 일반화하는 것에 주의해야 한다. 본 연구가 제시한 증거 기반 평가 프레임워크가 연구자와 실무자들이 방법론적 주장을 비판적으로 평가하고, 적절한 활용 범위를 설정하는 데 기여하기를 바란다.

---

## References

Argyle, L. P., Busby, E. C., Fulda, N., Gubler, J. R., Rytting, C., & Wingate, D. (2023). Out of one, many: Using language models to simulate human samples. *Political Analysis*, 31(3), 337-351.

Cao, Y., Zhou, L., Lee, S., Cabello, L., Chen, M., & Hershcovich, D. (2023). Assessing cross-cultural alignment between ChatGPT and human societies: An empirical study. *arXiv preprint arXiv:2303.17466*.

Dillion, D., Tandon, N., Gu, Y., & Gray, K. (2023). Can AI language models replace human participants? *Trends in Cognitive Sciences*, 27(7), 597-600.

Durmus, E., Nguyen, K., Liao, T. I., Schiefer, N., Askell, A., Bakhtin, A., ... & Ganguli, D. (2024). Towards measuring the representation of subjective global opinions in language models. *arXiv preprint arXiv:2306.16388*.

Horton, J. J. (2023). Large language models as simulated economic agents: What can we learn from homo silicus? *NBER Working Paper*, (w31122).

Jakesch, M., Hancock, J. T., & Naaman, M. (2023). Human heuristics for AI-generated language are flawed. *Proceedings of the National Academy of Sciences*, 120(11), e2208839120.

Motoki, F., Neto, V. P., & Rodrigues, V. (2024). More human than human: Measuring ChatGPT political bias. *Public Choice*, 198(1), 3-23.

Ornstein, J. T., Blasingame, E. N., & Truscott, J. S. (2024). How to train your stochastic parrot: Large language models for political texts. *Political Analysis*, 32(1), 117-134.

Park, J. S., O'Brien, J. C., Cai, C. J., Morris, M. R., Liang, P., & Bernstein, M. S. (2023). Generative agents: Interactive simulacra of human behavior. *Proceedings of the 36th Annual ACM Symposium on User Interface Software and Technology*, 1-22.

Santurkar, S., Durmus, E., Ladhak, F., Lee, C., Liang, P., & Hashimoto, T. (2023). Whose opinions do language models reflect? *arXiv preprint arXiv:2303.17548*.

Törnberg, P., Petrova, M., & Liao, Y. (2024). Simulating social media using large language models to evaluate alternative news feed algorithms. *arXiv preprint arXiv:2310.05984*.

Wei, J., Wang, X., Schuurmans, D., Bosma, M., Xia, F., Chi, E., ... & Zhou, D. (2022). Chain-of-thought prompting elicits reasoning in large language models. *Advances in Neural Information Processing Systems*, 35, 24824-24837.

---

## Appendices

### Appendix A: 페르소나 상세 설계

100개 페르소나의 인구학적 분포 및 설계 원칙은 `results/personas/personas_100.json` 참조.

### Appendix B: 실험별 상세 결과

각 실험의 원시 데이터 및 상세 분석 결과:
- 기본 시뮬레이션: `results/simulation/`
- Temperature 최적화: `results/temperature_optimization/`
- CoT 실험: `results/task4_cot_experiment/`
- 프롬프트 엔지니어링: `results/prompt_experiment/`
- 모델 비교: `results/gpt5_efficient_comparison/`

### Appendix C: 통계 분석 코드

분석에 사용된 Python 코드: `code/` 디렉토리 참조.

---

*본 논문은 2025년 12월 27일 작성되었습니다.*
